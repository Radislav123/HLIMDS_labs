%!TEX TS-program = xelatex

% Шаблон документа LaTeX создан в 2018 году
% Алексеем Подчезерцевым
% В качестве исходных использованы шаблоны
% 	Данилом Фёдоровых (danil@fedorovykh.ru) 
%		https://www.writelatex.com/coursera/latex/5.2.2
%	LaTeX-шаблон для русской кандидатской диссертации и её автореферата.
%		https://github.com/AndreyAkinshin/Russian-Phd-LaTeX-Dissertation-Template

\documentclass[a4paper,14pt]{article}

\input{data/preambular.tex}
\begin{document} % конец преамбулы, начало документа
    \input{data/title.tex}
    \tableofcontents
    \pagebreak


    \section{Задание}

    Бригада №5, вариант 1, плата DE10-nano.

    \begin{enumerate}
        \item Разработать на высокоуровневом языке программирования модель сети Хебба, способную распознать не менее 8 различных букв;
        \item Разработать модель нейрона на Verilog, произвести моделирование;
        \item Объединить нейроны, определить точность распознавания;
        \item Определить зависимость потребления ресурсов от количества нейронов;
        \item Выполнить прототипирование сети.
    \end{enumerate}


    \section{Выполнение работы}

    \subsection{Разработка сети}

    Была создана модель сети Хебба с помощью языка программирования Python.
    Низким уровнем сигнала был принят 0, а высоким -- 1.
    Кроме того, была написана дополнительная логика для сохранения полученной модели в код на Verilog,
    а так же проверки на переполнение полученной модели.

    Исходный код нейрона:
    {\small \VerbatimInput{../hebbian_net_lab_02/net/neuron.py}}

    Исходный код слоя:
    {\small \VerbatimInput{../hebbian_net_lab_02/net/layers.py}}

    Исходный код модели:
    {\small \VerbatimInput{../hebbian_net_lab_02/net/models.py}}

    Исходный код верхнеуровневого модуля:
    {\small \VerbatimInput{../hebbian_net_lab_02/example_03.py}}

    Результат запуска:
    {\small \VerbatimInput{logs/example_03.txt}}

    Программа отображает прогресс выполнения и может индицировать о досрочном завершении.
    После отображается ожидаемое и предсказанное значение для каждого символа и сам символ.
    В самом конце генерируется фрагмент кода для тестирования устройства.
    Созданный код нейрона и веса автоматически сохраняются после обучения.

    \subsection{Разработка сети на Verilog}

    Полученный код нейрона на языке Verilog:
    {\small \VerbatimInput{../de10-nano/neuron.v}}
    Для подсчета суммы использовалась оптимизация, которая позволяет сократить длительность подсчета суммы с линейного времени от размера изображения до логарифма от этого значения.
    Кроме того, операция умножения была заменена тернарным оператором, так как всего возможно 2 ситуации -- умножение на 0 и на 1.
    В первом случае результат 0, в другом -- то же самое число.
    Результат симуляции малой версии нейрона на примере из методических указаний представлен на рис.~\ref{fig:sim_small}.

    \begin{figure}[H]
        \centering
        \includegraphics[width=\linewidth]{images/sim_small}
        \caption{Симуляция малого нейрона}
        \label{fig:sim_small}
    \end{figure}

    \subsection{Объединение нейронов}

    Было выполнено объединение нейронов с помощью конструкции generate.
    Однако, симулятор Icarus Verilog требовал имени для каждого инстанса нейрона, поэтому цикл был развернут вручную.

    {\small \VerbatimInput{../de10-nano/layer.v}}

    Было проведена симуляция и тестирование сети (рис.~\ref{fig:sim_test}).
    По результатам тестирования предсказание сети на Python совпало с результатом симуляции Verilog,
    то есть сеть идеально распознавала элементы.
    Такое высокое качество было достигнуто за счёт подбора хорошей разметки.
    Стандартные варианты разметки не давали приличного качества даже на высокоуровневых языках.
    Это связано с несовершенствами сети Хебба.

    \begin{figure}[H]
        \centering
        \includegraphics[width=\linewidth]{images/sim_test}
        \caption{Симуляция слоя сети}
        \label{fig:sim_test}
    \end{figure}

    \subsection{Потребление ресурсов}
    Итоговая схема потребляет 1 логический элемент.
    На каждый пиксель изображения и на каждый выход сети расходуется по 1 пину.
    На сеть с 100 выходов тратится 120 пинов и 1 логический элемент (рис.~\ref{fig:plot}).
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.5\linewidth]{images/plot}
        \caption{Потребление ресурсов}
        \label{fig:plot}
    \end{figure}


    \section{Исходные коды}

    Исходные коды доступны на \href{https://github.com/AsciiShell/hse_hlimds_labs}
    {https://github.com/AsciiShell/hse\_hlimds\_labs}.

    Pull request работы \href{https://github.com/AsciiShell/hse_hlimds_labs/pull/2}
    {https://github.com/AsciiShell/hse\_hlimds\_labs/pull/2}.

    Релизы \href{https://github.com/AsciiShell/hse_hlimds_labs/releases}
    {https://github.com/AsciiShell/hse\_hlimds\_labs/releases}.


    \section{Выводы по работе}
    В ходе работы была изучена сеть Хебба, разобран принцип ее работы, особенности обучения сети.
    Были подобраны изображения и разметка, позволяющая идеально точно выполнять работу сети.
    Была создана программа, позволяющая перенести обученную сеть на Verilog.
    Проведено тестирование сети, получены результаты точности распознавания, потребления ресурсов.
    Итоговый вариант был записан на плату.

\end{document} % конец документа
